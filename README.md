## Inspiration
The inspiration behind EchoSense stemmed from a collective desire to enhance the lives of the visually impaired community. Witnessing their daily challenges ignited a passion to develop an innovative solution that would empower independence and safety.

## What it does
This technology empowers the visually impaired by detecting obstacles in real-time. This is important especially since traditional white canes have blind spots which do not allow the user to detect objects from the knees above. Our product uses a secondary ultrasonic sensor to detect such collisions, which is coupled with a personalized app that considers individual height and calculates when it should notify the user of incoming collisions.

## How we built it
We used Android Studio as our ide and then Java as the programming language. We then used Raspberry Pi to code two ultrasonic sensors using Python and got the hardware and the server working.

## Challenges we ran into
We ran into many challenges during the production of EchoSense which almost made us abandon the project. One of the main challenges we ran into is to get the audio to work whenever it detects an object coming nearby. The other challenge was to get the app to connect with the Raspberry Pi. And biggest challenge that took the longest to overcome was the Raspberry Pi OS to work with the modules.

## Accomplishments that we're proud of
We are proud that we were able to create a product that has a positive impact on the world. We are also proud that we were able to use networking skills and make a mobile app that communicates with the Pi.

## What we learned
Throughout this journey, we learned the value of collaboration, persistence, and empathy-driven design. Overcoming technical hurdles and refining our solution taught us the importance of holistic thinking and the profound impact of technology on accessibility.

## What's next for EchoSense
Our goal for EchoSense goes beyond the present. We are dedicated to bringing this innovative project to life by developing functional prototypes. Moreover, we are working hard to enhance the user experience by adding GPS functionality. In our future versions, the integration of vibrational signals will mark a significant step forward in providing an all-inclusive solution for the visually impaired community.
